# Examen Pr치ctico - Sistemas Distribuidos

Este proyecto implementa un sistema de procesamiento dual (procesos e hilos) y un sistema de almacenamiento distribuido (Docker y MongoDB) como parte del examen de Sistemas Distribuidos.

## 游늬 Parte 1: Procesamiento Distribuido (Hilos vs Procesos)

Esta parte compara el rendimiento de Hilos contra Procesos para procesar una lista de tareas con dificultad variable.

### 游 Ejecuci칩n (Parte 1)

1.  Abre una terminal en la ra칤z del proyecto.
2.  Ejecuta el script:
    ```bash
    python part1-processes-threads/task_processor.py
    ```

### 游늳 An치lisis de Resultados (Parte 1)

- **Hilos:** `Tiempo con hilos: 0.50s` (Aprox.)
- **Procesos:** `Tiempo con procesos: 1.50s` (Aprox.)

**Conclusi칩n:** Para esta simulaci칩n, **los hilos son mucho m치s r치pidos**.

La simulaci칩n usa `time.sleep()`, que es una operaci칩n **I/O-Bound** (limitada por espera). Cuando un hilo ejecuta `time.sleep()`, libera el GIL (Global Interpreter Lock) de Python, permitiendo que otro hilo se ejecute. Esto da como resultado un paralelismo casi real.

Los procesos son m치s lentos porque crear un proceso nuevo (hacer "fork" o "spawn") es una operaci칩n mucho m치s costosa y pesada para el sistema operativo que crear un hilo.

> **Nota:** Si la tarea fuera **CPU-Bound** (un c치lculo matem치tico pesado), los **Procesos** ganar칤an, ya que podr칤an usar m칰ltiples n칰cleos de CPU simult치neamente, mientras que los hilos se bloquear칤an entre s칤 por el GIL.

### 游 C칩mo se evitan las Condiciones de Carrera

- **En Hilos:** Se usa un `threading.Lock()` (`self.lock`). La secci칩n `with self.lock:` asegura que solo un hilo a la vez pueda acceder y modificar el contador `self.thread_tasks_completed`.
- **En Procesos:** Se usa un `multiprocessing.Value('i', 0)`. Este objeto tiene su propio `lock` incorporado. La secci칩n `with counter.get_lock():` asegura que solo un proceso a la vez pueda modificar el contador `counter.value`, evitando que los procesos se sobrescriban entre s칤.

---

## 游닍 Parte 2: Almacenamiento Distribuido (MongoDB)

Esta parte simula un sistema de archivos distribuido usando dos bases de datos MongoDB (mongo1, mongo2) y un cliente de Python (`storage_client`), todos orquestados por Docker.

### 游 Ejecuci칩n (Parte 2)

1.  Aseg칰rate de tener Docker Desktop corriendo.
2.  Abre una terminal en la ra칤z del proyecto (donde est치 `docker-compose.yml`).
3.  Levanta los servicios:
    ```bash
    docker-compose up --build -d
    ```
4.  El script de Python se ejecuta autom치ticamente. Para ver los resultados (la distribuci칩n de los 100 documentos), revisa los logs del cliente:
    ```bash
    docker-compose logs storage_client
    ```
5.  **Resultado esperado (Logs):**
    ```
    Estad칤sticas de distribuci칩n: {'mongo1': 48, 'mongo2': 52}
    (Los n칰meros pueden variar)
    ```

### 游댕 Conceptos Aplicados (Parte 2)

- **Distribuci칩n de datos:** El script `storage_system.py` distribuye los datos usando `random.choice()`, asignando cada documento nuevo a `mongo1` o `mongo2` al azar.
- **Transparencia de b칰squeda:** El m칠todo `find_document()` busca en _todos_ los nodos (`mongo1` y `mongo2`). El usuario no necesita saber d칩nde est치 guardado el dato; el sistema lo encuentra por 칠l.
